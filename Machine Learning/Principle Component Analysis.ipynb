{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b16177",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction using PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff194d",
   "metadata": {},
   "source": [
    "# PCA (Principal Component Analysis)\n",
    "\n",
    "**Definition:** Unsupervised dimensionality reduction that transforms correlated features into **orthogonal principal components (PCs)** maximizing **variance**.\n",
    "\n",
    "---\n",
    "\n",
    "**Purpose:** Reduce dimensionality, remove correlation, denoise data, aid visualization.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Facts:**  \n",
    "- PCs are **linear combinations** of original features  \n",
    "- PCs are **orthogonal** (uncorrelated)  \n",
    "- PC1 has **maximum variance**, subsequent PCs capture remaining variance  \n",
    "\n",
    "---\n",
    "\n",
    "**Mathematics**\n",
    "$$\n",
    "X \\in \\mathbb{R}^{n \\times p} \\quad \\text{(mean-centered data matrix)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma = \\frac{1}{n} X^T X \\quad \\text{(covariance matrix)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma v_i = \\lambda_i v_i \\quad \n",
    "v_i = \\text{i-th principal component}, \\quad \n",
    "\\lambda_i = \\text{variance explained by PC}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Explained Variance (PC}_i) = \\frac{\\lambda_i}{\\sum_{j=1}^{p} \\lambda_j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "X = U \\Sigma V^T \\quad \\Rightarrow \\quad V = \\text{matrix of principal components (SVD)}\n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7971f",
   "metadata": {},
   "source": [
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344af2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41e1776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "iris_df = sns.load_dataset('iris')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5d16e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.057333      3.758000     1.199333\n",
       "std        0.828066     0.435866      1.765298     0.762238\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "iris_df.describe(),\n",
    "iris_df.shape,\n",
    "iris_df.isnull().sum()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f690fc",
   "metadata": {},
   "source": [
    "No nulls have been found\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77328d20",
   "metadata": {},
   "source": [
    "## Calculating accuracy with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b8a6a",
   "metadata": {},
   "source": [
    "### Against Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780de69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting features\n",
    "x = iris_df.drop(columns=['species'])\n",
    "y = iris_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6acb1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad36465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "s = StandardScaler()\n",
    "\n",
    "# If we standardize the data together, the train and test data become dependent and thus model results are skewed.\n",
    "x_train_s = s.fit_transform(x_train)\n",
    "x_test_s = s.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ffff8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Raw Data:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=67)\n",
    "# fit the model\n",
    "clf.fit(x_train_s, y_train)\n",
    "# generate predictions\n",
    "y_pred = clf.predict(x_test_s)\n",
    "\n",
    "print(\"Accuracy on Raw Data: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb2ddc",
   "metadata": {},
   "source": [
    "### Against PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8f4227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on PCA Data:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "pca = PCA(n_components = 2)\n",
    "x_train_pca = pca.fit_transform(x_train_s)\n",
    "x_test_pca = pca.transform(x_test_s)\n",
    "\n",
    "# Train classifier against PCA data\n",
    "clf_pca = RandomForestClassifier(n_estimators=100, random_state=67)\n",
    "clf_pca.fit(x_train_pca, y_train)\n",
    "y_pred_pca2 = clf_pca.predict(x_test_pca)\n",
    "\n",
    "print(\"Accuracy on PCA Data: \", metrics.accuracy_score(y_test, y_pred_pca2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b4e46",
   "metadata": {},
   "source": [
    "Since 2 is not giving a good result, then lets try again with 3 components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d908233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on PCA Data:  0.9\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "pca = PCA(n_components = 3)\n",
    "x_train_pca = pca.fit_transform(x_train_s)\n",
    "x_test_pca = pca.transform(x_test_s)\n",
    "\n",
    "# Train classifier against PCA data\n",
    "clf_pca = RandomForestClassifier(n_estimators=1000, random_state=67)\n",
    "clf_pca.fit(x_train_pca, y_train)\n",
    "y_pred_pca3 = clf_pca.predict(x_test_pca)\n",
    "\n",
    "print(\"Accuracy on PCA Data: \", metrics.accuracy_score(y_test, y_pred_pca3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0068dfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on PCA Data:  0.9\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "pca = PCA(n_components = 4)\n",
    "x_train_pca = pca.fit_transform(x_train_s)\n",
    "x_test_pca = pca.transform(x_test_s)\n",
    "\n",
    "# Train classifier against PCA data\n",
    "clf_pca = RandomForestClassifier(n_estimators=100, random_state=67)\n",
    "clf_pca.fit(x_train_pca, y_train)\n",
    "y_pred_pca4 = clf_pca.predict(x_test_pca)\n",
    "\n",
    "print(\"Accuracy on PCA Data: \", metrics.accuracy_score(y_test, y_pred_pca4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
